

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tensors &mdash; Practical Machine Learning  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx_lesson.css?v=e9df6548" />
      <link rel="stylesheet" type="text/css" href="../../_static/term_role_formatting.css?v=4194e21c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx_rtd_theme_ext_color_contrast.css?v=8e8ea19f" />
      <link rel="stylesheet" type="text/css" href="../../_static/overrides.css?v=c88db32d" />

  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=187304be"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=35a8b989"></script>
      <script src="../../_static/minipres.js?v=a0d29692"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../" class="icon icon-home">
            Practical Machine Learning
              <img src="../../_static/ENCCS.jpg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Software setup</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../00-software-setup/">Setting Up Programming Environment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Lesson episodes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../01-intro-to-ML/">Introduction to Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../02-fundamentals-of-ML/">Fundamentals of Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../03-scientific-data-for-ML/">Scientific Data for Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../04-data-preparation-for-ML/">Data Preparation for Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../05-supervised-ML-classification/">Supervised Learning (I): Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../06-supervised-ML-regression/">Supervised Learning (II): Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../07-unsupervised-ML-clustering/">Unsupervised Learning (I): Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../08-unsupervised-ML-dimensionality-reduction/">Unsupervised Learning (II): Dimensionality Reduction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../quick-reference/">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide/">Instructor’s guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://enccs.se/lessons/">All lessons</a></li>
<li class="toctree-l1"><a class="reference external" href="https://enccs.se/">ENCCS</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../">Practical Machine Learning</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Tensors</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/ENCCS/practical-machine-learning/blob/main/content/jupyter-notebooks/3-Tensor.ipynb" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="tensors">
<h1>Tensors<a class="headerlink" href="#tensors" title="Link to this heading"></a></h1>
<section id="what-is-tensor">
<h2>1. What is Tensor<a class="headerlink" href="#what-is-tensor" title="Link to this heading"></a></h2>
<p>A <strong>tensor</strong> is a mathematical object that generalizes scalars, vectors, and matrices to higher dimensions. It’s essentially a container for data that can be indexed in multiple dimensions.</p>
<p><img alt="scalar-vector-matrix-tensor.png" src="data:image/png;base64,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" /></p>
<p><strong>Tensor</strong> vs <strong>ndarray</strong></p>
<ul class="simple">
<li><p>Tensor is similar to the fundamental object in Numpy called ndarray</p></li>
<li><p>ndarray is defined as an n-dimensional homogeneous array of fixed-size items</p></li>
</ul>
<p><strong>Advantages of Tensor</strong></p>
<ul class="simple">
<li><p>Tensor operations are performed significantly faster using GPUs</p></li>
<li><p>Tensors can be stored and manipulated at scale using distributed processing on multi GPUs and GPUs and across multiple servers</p></li>
<li><p>Tensors keep track of the graph of computations that created them</p></li>
<li><p>Tensors are much more than a special sort of multi-dimensional arrays</p></li>
<li><p>Interactions with each other such that transforming the tensors as a whole means that each tensor follows a particular transformation rule</p></li>
</ul>
</section>
<section id="creat-tensors">
<h2>2. Creat Tensors<a class="headerlink" href="#creat-tensors" title="Link to this heading"></a></h2>
<section id="from-python-objects">
<h3>2.1 From Python objects<a class="headerlink" href="#from-python-objects" title="Link to this heading"></a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="n">zero_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">])</span>
<span class="n">oneD_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">twoD_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span> <span class="c1"># can be list or tuple</span>
<span class="n">treD_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">]]])</span>

<span class="c1"># tensor.size()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;zero_tensor = </span><span class="si">{</span><span class="n">zero_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">zero_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;oneD_tensor = </span><span class="si">{</span><span class="n">oneD_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">oneD_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;twoD_tensor = </span><span class="si">{</span><span class="n">twoD_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">twoD_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;treD_tensor = </span><span class="si">{</span><span class="n">treD_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">treD_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="from-numpy-objects">
<h3>2.2 From Numpy objects<a class="headerlink" href="#from-numpy-objects" title="Link to this heading"></a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># pytorch</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">twoD_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;twoD_tensor = </span><span class="si">{</span><span class="n">twoD_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">twoD_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">twoD_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;twoD_tensor = </span><span class="si">{</span><span class="n">twoD_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">twoD_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">tensor_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np_array</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;tensor_x = </span><span class="si">{</span><span class="n">tensor_x</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">tensor_x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tensorflow</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>

<span class="c1"># from a Python list</span>
<span class="n">tensor_tf1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tensor_tf1</span><span class="p">)</span>

<span class="c1"># from a NumPy array</span>
<span class="n">tensor_tf2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tensor_tf2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="from-functions-to-create-tensors">
<h3>2.3 From functions to create tensors<a class="headerlink" href="#from-functions-to-create-tensors" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">torch.zeros()</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.zeros_like()</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.zeros()</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.zeros_like()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.ones()</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.ones_like()</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.ones()</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.ones_like()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.empty()</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.rand_like()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.full()</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.full_like()</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">empty_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;empty_tensor = </span><span class="si">{</span><span class="n">empty_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">empty_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">zeros_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;zeros_tensor = </span><span class="si">{</span><span class="n">zeros_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">zeros_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">ones_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;ones_tensor = </span><span class="si">{</span><span class="n">ones_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">ones_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">full_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="mf">0.12</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;full_tensor = </span><span class="si">{</span><span class="n">full_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">full_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----------------------------------------------------</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_zeros = </span><span class="si">{</span><span class="n">a_zeros</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">a_zeros</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_ones = </span><span class="si">{</span><span class="n">a_ones</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">a_ones</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_rand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_rand = </span><span class="si">{</span><span class="n">a_rand</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">a_rand</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_full</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">a_rand</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span> <span class="c1"># here this matrix should be filled with `7`</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_full = </span><span class="si">{</span><span class="n">a_full</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">a_full</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generating tensor using tensorflow</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>

<span class="n">zeros_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;zeros_tensor = </span><span class="si">{</span><span class="n">zeros_tensor</span><span class="si">}</span><span class="s1"> and its tensor shape = </span><span class="si">{</span><span class="n">zeros_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">ones_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;ones_tensor = </span><span class="si">{</span><span class="n">ones_tensor</span><span class="si">}</span><span class="s1"> and its tensor shape = </span><span class="si">{</span><span class="n">ones_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># torch.eye(n)</span>

<span class="n">tensor_eye</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;tensor_eyee = </span><span class="se">\n</span><span class="si">{</span><span class="n">tensor_eye</span><span class="si">}</span><span class="se">\n</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">tensor_eye</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># torch.linspace(start, end, steps)</span>
<span class="c1"># torch.logspace(start, end, steps)</span>

<span class="n">lin</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;lin = </span><span class="si">{</span><span class="n">lin</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">lin</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">log</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;log = </span><span class="si">{</span><span class="n">log</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">log</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="random-tensors">
<h3>2.4 Random tensors<a class="headerlink" href="#random-tensors" title="Link to this heading"></a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123456</span><span class="p">)</span> <span class="c1"># to keep data reproduciable</span>

<span class="c1"># generate values from a uniform distribution on the interval [0, 1)</span>
<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># standard normal distribution</span>
<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># `torch.randint(a, b, (m, n))` generate a `m*n` integers from `a` to `b`</span>
<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># `torch.randperm(n)` to create a tensor with a random permutation of integers</span>
<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor size = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="tensor-s-properties">
<h2>3. Tensor’s properties<a class="headerlink" href="#tensor-s-properties" title="Link to this heading"></a></h2>
<section id="tensor-shape">
<h3>3.1 Tensor.shape<a class="headerlink" href="#tensor-shape" title="Link to this heading"></a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor shape = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor shape = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor shape = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor shape = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="tensor-ndim">
<h3>3.2 Tensor.ndim<a class="headerlink" href="#tensor-ndim" title="Link to this heading"></a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor ndim = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor ndim = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor ndim = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor ndim = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="tensor-dtype">
<h3>3.3 Tensor.dtype<a class="headerlink" href="#tensor-dtype" title="Link to this heading"></a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_tensor_int</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor_int = </span><span class="si">{</span><span class="n">a_tensor_int</span><span class="si">}</span><span class="s1"> and its tensor dtype = </span><span class="si">{</span><span class="n">a_tensor_int</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">b_tensor_flt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span> <span class="c1"># can use `float64`</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b_tensor_flt = </span><span class="si">{</span><span class="n">b_tensor_flt</span><span class="si">}</span><span class="s1"> and its tensor dtype = </span><span class="si">{</span><span class="n">b_tensor_flt</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># torch.int8, torch.int16, torch.int32, torch.int64, torch.float16, torch.float32, torch.float64</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-----------------------------------------------------------------</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># data type conversion</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------- data type conversion (two methods) -------</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_tensor_flt1</span> <span class="o">=</span> <span class="n">a_tensor_int</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor_flt1 = </span><span class="si">{</span><span class="n">a_tensor_flt1</span><span class="si">}</span><span class="s1"> and its tensor dtype = </span><span class="si">{</span><span class="n">a_tensor_flt1</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_tensor_flt1</span> <span class="o">=</span> <span class="n">a_tensor_int</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="c1"># or .to(dtype=torch.double)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor_flt1 = </span><span class="si">{</span><span class="n">a_tensor_flt1</span><span class="si">}</span><span class="s1"> and its tensor dtype = </span><span class="si">{</span><span class="n">a_tensor_flt1</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="tensor-operations">
<h2>4. Tensor operations<a class="headerlink" href="#tensor-operations" title="Link to this heading"></a></h2>
<section id="indexing">
<h3>4.1 Indexing<a class="headerlink" href="#indexing" title="Link to this heading"></a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123456</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor shape = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_tensor_row</span> <span class="o">=</span> <span class="n">a_tensor</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;A ROW of a_tensor = </span><span class="si">{</span><span class="n">a_tensor_row</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">a_tensor_col</span> <span class="o">=</span> <span class="n">a_tensor</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;A COL of a_tensor = </span><span class="si">{</span><span class="n">a_tensor_col</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">a_tensor_cubic</span> <span class="o">=</span> <span class="n">a_tensor</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;A inner cubic of a_tensor = </span><span class="se">\n</span><span class="si">{</span><span class="n">a_tensor_cubic</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># use indexing  to extract data that meets some criteria</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Extra data &gt; 0.5 = &quot;</span><span class="p">,</span> <span class="n">a_tensor_cubic</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Extra data &gt; 0.5 = &quot;</span><span class="p">,</span> <span class="n">a_tensor_cubic</span><span class="p">[</span><span class="n">a_tensor_cubic</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="combining-tensors">
<h3>4.2 Combining Tensors<a class="headerlink" href="#combining-tensors" title="Link to this heading"></a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">],[</span><span class="mi">13</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b_tensor = </span><span class="si">{</span><span class="n">b_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># using `torch.stack` to add new dimension and stacks -- creates a new dimension</span>
<span class="n">stack_tensor_dim0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">b_tensor</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># stack by rows</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;stack_tensor_dim0 = </span><span class="se">\n</span><span class="si">{</span><span class="n">stack_tensor_dim0</span><span class="si">}</span><span class="s1"> and its tensor shape = </span><span class="si">{</span><span class="n">stack_tensor_dim0</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">stack_tensor_dim1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">b_tensor</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># stack by columns</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;stack_tensor_dim1 = </span><span class="se">\n</span><span class="si">{</span><span class="n">stack_tensor_dim1</span><span class="si">}</span><span class="s1"> and its tensor shape = </span><span class="si">{</span><span class="n">stack_tensor_dim1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># using `torch.cat` to concatenates along existing dim -- extends an existing dimension.</span>
<span class="n">cat_tensor_dim0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">b_tensor</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># cat by rows</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;cat_tensor_dim0 = </span><span class="se">\n</span><span class="si">{</span><span class="n">cat_tensor_dim0</span><span class="si">}</span><span class="s1"> and its tensor shape = </span><span class="si">{</span><span class="n">cat_tensor_dim0</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">cat_tensor_dim1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">b_tensor</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># cat by columns</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;cat_tensor_dim1 = </span><span class="se">\n</span><span class="si">{</span><span class="n">cat_tensor_dim1</span><span class="si">}</span><span class="s1"> and its tensor shape = </span><span class="si">{</span><span class="n">cat_tensor_dim1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="split-tensors">
<h3>4.3 Split Tensors<a class="headerlink" href="#split-tensors" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Function</p></th>
<th class="head text-center"><p>Purpose</p></th>
<th class="head text-center"><p>Input Parameters</p></th>
<th class="head text-center"><p>Output</p></th>
<th class="head text-center"><p>Changes Shape?</p></th>
<th class="head text-center"><p>Splits Tensor?</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">torch.chunk</span></code></p></td>
<td class="text-center"><p>split into fixed number of chunks</p></td>
<td class="text-center"><p>chunks (int), dim</p></td>
<td class="text-center"><p>Tuple of tensors</p></td>
<td class="text-center"><p>No</p></td>
<td class="text-center"><p>Yes</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">torch.split</span></code></p></td>
<td class="text-center"><p>split into chunks of specified sizes</p></td>
<td class="text-center"><p>split_size_or_sections, dim</p></td>
<td class="text-center"><p>Tuple of tensors</p></td>
<td class="text-center"><p>No</p></td>
<td class="text-center"><p>Yes</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">torch.view</span></code></p></td>
<td class="text-center"><p>reshape tensor</p></td>
<td class="text-center"><p>New shape</p></td>
<td class="text-center"><p>Single tensor</p></td>
<td class="text-center"><p>Yes</p></td>
<td class="text-center"><p>No</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">torch.unbind</span></code></p></td>
<td class="text-center"><p>remove a dimension, split into slices</p></td>
<td class="text-center"><p>dim</p></td>
<td class="text-center"><p>Tuple of tensors</p></td>
<td class="text-center"><p>Yes (removes dim)</p></td>
<td class="text-center"><p>Yes</p></td>
</tr>
</tbody>
</table>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">101</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--------- torch.unbind(tensor) ---------&#39;</span><span class="p">)</span>
<span class="n">tensors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;first_tensor = </span><span class="si">{</span><span class="n">tensors</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">tensors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;first_tensor = </span><span class="si">{</span><span class="n">tensors</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--------- torch.split(tensor) ---------&#39;</span><span class="p">)</span>
<span class="n">tensors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># split by rows</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensors = </span><span class="si">{</span><span class="n">tensors</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">tensors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># split by cols</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensors = </span><span class="si">{</span><span class="n">tensors</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--------- torch.chunk(tensor) ---------&#39;</span><span class="p">)</span>

<span class="n">chunks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;chunks = </span><span class="si">{</span><span class="n">chunks</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;chunks[0] = </span><span class="si">{</span><span class="n">chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;chunks[1] = </span><span class="si">{</span><span class="n">chunks</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;chunks[2] = </span><span class="si">{</span><span class="n">chunks</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">chunks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;chunks = </span><span class="si">{</span><span class="n">chunks</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># `torch.view` provides an easy way to reshape a tensor</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;a_tensor = </span><span class="se">\n</span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">a_tensor</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;b_tensor = </span><span class="se">\n</span><span class="si">{</span><span class="n">b_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># `torch.flatten` method can be used to collapse the dimensions of a given tensor starting with a particular dimension</span>
<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;a_tensor = </span><span class="se">\n</span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;b_tensor = </span><span class="se">\n</span><span class="si">{</span><span class="n">b_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">c_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;c_tensor = </span><span class="se">\n</span><span class="si">{</span><span class="n">c_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">d_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;d_tensor = </span><span class="se">\n</span><span class="si">{</span><span class="n">d_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensor shapes = b:</span><span class="si">{</span><span class="n">b_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensor shapes = c:</span><span class="si">{</span><span class="n">c_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensor shapes = d:</span><span class="si">{</span><span class="n">d_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="build-in-math-functions">
<h3>4.4 Build-in Math Functions<a class="headerlink" href="#build-in-math-functions" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>pointwise operations</p></li>
<li><p>reduction functions</p></li>
<li><p>comparison functions</p></li>
<li><p>linear algebra operations</p></li>
<li><p>spectral and other math computations</p></li>
</ul>
<section id="pointwise-operations">
<h4>4.4.1 Pointwise operations<a class="headerlink" href="#pointwise-operations" title="Link to this heading"></a></h4>
<p>To perform an operation on each point in tensor individually and return a new tensor</p>
<ul class="simple">
<li><p>basic math functions, like <code class="docutils literal notranslate"><span class="pre">add()</span></code>, <code class="docutils literal notranslate"><span class="pre">sub()</span></code>, <code class="docutils literal notranslate"><span class="pre">mul()</span></code>, <code class="docutils literal notranslate"><span class="pre">div()</span></code>, <code class="docutils literal notranslate"><span class="pre">neg()</span></code>, and <code class="docutils literal notranslate"><span class="pre">true_divid()</span></code></p></li>
<li><p>functions for truncation, like <code class="docutils literal notranslate"><span class="pre">ceil()</span></code>, <code class="docutils literal notranslate"><span class="pre">clamp()</span></code>, <code class="docutils literal notranslate"><span class="pre">floor()</span></code>, <em>etc.</em></p></li>
<li><p>logical functions</p></li>
<li><p>trigonometry functions, like <code class="docutils literal notranslate"><span class="pre">sin()</span></code>, <code class="docutils literal notranslate"><span class="pre">cos()</span></code>, <em>etc.</em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensor a = </span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensor b = </span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensor a+b = </span><span class="si">{</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensor a+b = </span><span class="si">{</span><span class="n">a</span><span class="o">-</span><span class="n">b</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensor a+b = </span><span class="si">{</span><span class="n">a</span><span class="o">*</span><span class="n">b</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensor a+b = </span><span class="si">{</span><span class="n">a</span><span class="o">/</span><span class="n">b</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sin of tensor a = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cos of tensor b = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">13</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>

<span class="c1"># `dot()` allows you to compute the dot product of tensors</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensor dot = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># `cross()` allows to compute cross product of two tensors</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensor cross = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cross</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="reduction-functions">
<h4>4.4.2 Reduction functions<a class="headerlink" href="#reduction-functions" title="Link to this heading"></a></h4>
<p>Reduce numbers down to a single number or a smaller set of numbers</p>
<ul class="simple">
<li><p>results in reducing the dimensionality or rank of a tensor</p></li>
<li><p>include statistical functions such as mean, median, mode, <em>etc.</em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean   of tensor a = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Median of tensor b = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mode   of tensor b = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Standard deviation of tensor a = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="comparison-functions">
<h4>4.4.3 Comparison functions<a class="headerlink" href="#comparison-functions" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>compare all values within a tensor or compare values of two different tensors</p></li>
<li><p>functions to find minimum or maximum value, sort tensor values, test tensor status or conditions, <em>etc.</em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123456</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;a_tensor = </span><span class="se">\n</span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;b_tensor = </span><span class="se">\n</span><span class="si">{</span><span class="n">b_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">ge_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">b_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ge_torch = </span><span class="se">\n</span><span class="si">{</span><span class="n">ge_torch</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">lt_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">b_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;lt_torch = </span><span class="se">\n</span><span class="si">{</span><span class="n">lt_torch</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># torch.le(), torch.eq(), torch.ne()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># `any` and `all` methods enable to check whether a given condition is true in any or all cases</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor A = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">a</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">a</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">a</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">a</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="linear-algebra-operations">
<h4>4.4.4 Linear algebra operations<a class="headerlink" href="#linear-algebra-operations" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>enable matrix operations and are essential for DL computations</p></li>
<li><p>functions for matrix computations and tensor computations</p></li>
<li><p>PyTorch has a module called <code class="docutils literal notranslate"><span class="pre">torch.linalg</span></code> than contains a set of build-in functions that are based on BLAS and LAPACK standardized libraries</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute dot product (scalar) of two 1D tensors</span>
<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

<span class="n">ab_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">b_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Torch.matmul for two 1D scalarss = </span><span class="si">{</span><span class="n">ab_tensor</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># compute matrix-matrix product (2D tensor) of two 2D tensors</span>
<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>

<span class="n">ab_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">b_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Torch.matmul for two 2D matrices = </span><span class="si">{</span><span class="n">ab_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute a matrix product of multiple 2D tensors</span>
<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">c_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">d_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">abcd_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">b_tensor</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">c_tensor</span><span class="p">,</span> <span class="n">d_tensor</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Torch.matmul for four 2D matrices = </span><span class="se">\n</span><span class="si">{</span><span class="n">abcd_tensor</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">abcd_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">multi_dot</span><span class="p">((</span><span class="n">a_tensor</span><span class="p">,</span> <span class="n">b_tensor</span><span class="p">,</span> <span class="n">c_tensor</span><span class="p">,</span> <span class="n">d_tensor</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Torch.linalg.multi_dot for four 2D matrices = </span><span class="se">\n</span><span class="si">{</span><span class="n">abcd_tensor</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute eigenvalues and eigenvectors</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor A = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">eigenvalues</span><span class="p">,</span> <span class="n">eigenvectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Eigenvalues = </span><span class="si">{</span><span class="n">eigenvalues</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Eigenvectors = </span><span class="si">{</span><span class="n">eigenvectors</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># `addbmm` (bmm = batch matrix-matrix product) to perform computation p*m+q*[a1*b1+a2*b2+...]</span>
<span class="c1"># where p and q are scalars, and m, a1, b1, a2, and b2 are tensors</span>

<span class="c1"># Note that `addbmm` takes parameters p and q with default values equal to one</span>
<span class="c1"># and that tensors such as a1 and a2 are provided by stacking them along 1st dimension</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;shapes of a, b, and m tensors are </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, and </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">addbmm</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">addbmm</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># `baddbmm` to perform p1 * m + q * [a1 * b1], p2 * m + q * [a2 * b2], ...</span>
<span class="c1"># where p and q are scalars, and m, p1, a1, b1, p2, a2, and b2 are tensors</span>

<span class="c1"># Note that `baddbmm` takes parameters p and q with default values equal to one</span>
<span class="c1"># and that tensors such as p1, a1, and a2 are provided by stacking them along 1st dimension</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;shapes of a, b, and m tensors are </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, and </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">baddbmm</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">baddbmm</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">baddbmm</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># `bmm` to perform batch-wise matrix multiplication for tensor</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;shapes of a, b tensors are </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,and </span><span class="si">{</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># `addmm` is a non-batch version of addbmm that allows to perform computation p * m + q * a * b</span>
<span class="c1"># where p and q are scalars, and m, a, and b are tensors</span>

<span class="c1"># Note that `addmm` takes parameters p and q with default values equal to one</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;shapes of a, b, and m tensors are </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, and </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">addmm</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">addmm</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">addmm</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># `addmv` (matrix-vector) allows to perform computation p * m + q * a * b</span>
<span class="c1"># where p and q are scalars, m and a are matrices, and b is a vector</span>

<span class="c1"># Note that `addmv` takes parameters p and q with default values equal to one</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;shapes of a, b, and m tensors are </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, and </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">addmv</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">addmv</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">addmv</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">addr</span></code> allows to perform an outer product of two vectors and add it to a given matrix</p>
<ul class="simple">
<li><p>outer product of two vectors in linear algebra is a matrix</p></li>
<li><p><em>e.g.</em>, if you have a vector V with m elements (1 dimension) and another vector U with n elements (1 dimension), then outer product of V and U will be a matrix with m × n shape</p>
<ul>
<li><p>V= [v1, v2, v3…, vm]</p></li>
<li><p>U = [u1, u2, ……un]</p></li>
</ul>
</li>
</ul>
<p>V ⊕ U = A =
[ v1u1, v1u2, …. , v1um,’\n’
v2u1, v2u2, …. , v2um,’\n’
…..
vnu1, vnu2, …. , vnum]</p>
<p>In PyTorch, function expects 1st argument as matrix to which we need to add resultant outer product, followed by vectors for which outer product needs to be computed</p>
<ul class="simple">
<li><p>below we create two vectors (a and b) with three elements each, and perform an outer product to create a 3 × 3 matrix, which is then added to another matrix (m)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">a</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;shapes of a, b, and m tensors are </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, and </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">addr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">addr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="activation-functions">
<h3>4.5 Activation functions<a class="headerlink" href="#activation-functions" title="Link to this heading"></a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_tensor</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using sigmoid function = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using tanh    function = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using log1p   function = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using erf     function = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">erf</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using erfinv  function = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">erfinv</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using sigmoid function = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using tanh    function = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using log1p   function = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using erf     function = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">erf</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using erfinv  function = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">erfinv</span><span class="p">(</span><span class="n">a_tensor</span><span class="p">)</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="tensors-in-dl-frameworks">
<h2>5. Tensors in DL frameworks<a class="headerlink" href="#tensors-in-dl-frameworks" title="Link to this heading"></a></h2>
<section id="tensor-device-cpu-vs-cuda">
<h3>5.1 Tensor.device (CPU vs CUDA)<a class="headerlink" href="#tensor-device-cpu-vs-cuda" title="Link to this heading"></a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="c1"># &#39;cpu by default&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span> <span class="c1"># cuda for gpu, there is no error if I have GPU</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PyTorcch version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span>
<span class="c1"># device = &#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span><span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b_tensor = </span><span class="si">{</span><span class="n">b_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">b_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="c1"># print(a_tensor + b_tensor) # not compatible as is on CPU and one is on GPU</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Moving Tensors between CPUs and GPUs</strong></p>
<ul class="simple">
<li><p>Transfer data from CPU to GPU</p></li>
<li><p>After training, output Tensors are produced in GPU</p></li>
<li><p>Output data requires preprocessing</p></li>
<li><p>Some  preprocessing libraries don’t support Tensors and expect a Numpy array</p></li>
<li><p>Numpy supports only data in GPU, and we need to move data from GPU to CPU</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data from CPU to GPU -- 3 methods</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span><span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># 1. `Tensor.cuda()`</span>
<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">a_tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b_tensor = </span><span class="si">{</span><span class="n">b_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">b_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># 2. `Tensor.to(&quot;cuda&quot;)`</span>
<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">a_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b_tensor = </span><span class="si">{</span><span class="n">b_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">b_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># 3. `Tensor.to(&quot;cuda:0&quot;)`</span>
<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">a_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b_tensor = </span><span class="si">{</span><span class="n">b_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">b_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data from GPU to CPU -- 2 methods</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">4</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># 1. `Tensor.cpu()` with `requires_grad=False`</span>
<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">a_tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b_tensor = </span><span class="si">{</span><span class="n">b_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">b_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># 2. `Tensor.detach().cpu() with `requires_grad=True`</span>
<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">a_tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b_tensor = </span><span class="si">{</span><span class="n">b_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">b_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tensor to numpy arrays</span>

<span class="n">a_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_tensor = </span><span class="si">{</span><span class="n">a_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">a_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">a_array</span> <span class="o">=</span> <span class="n">a_tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;a_array = </span><span class="si">{</span><span class="n">a_array</span><span class="si">}</span><span class="s1"> and its array device = </span><span class="si">{</span><span class="n">a_array</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">b_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a_array</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b_tensor = </span><span class="si">{</span><span class="n">b_tensor</span><span class="si">}</span><span class="s1"> and its tensor device = </span><span class="si">{</span><span class="n">b_tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, The contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>